{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Tagger\n",
    "\n",
    "It takes input sentence and assign part of speech such as Noun, Pronoun, Verb, Adjective(ADJ) etcetera with each word in the sentence.\n",
    "\n",
    "for more details: https://github.com/rameshjesswani/Semantic-Textual-Similarity/wiki/Part-of-Speech-Tagging\n",
    "\n",
    "\n",
    "# Entity Recognition Recognition\n",
    "\n",
    "Named Entities are used to determine the noun phrases in the sentence. Furthermore noun phrases can be name of organization, locations, person, faculty, Geo-political entities(GPE) which includes city, state/province, and country.\n",
    "\n",
    "Moreover, named entity recognition provided by SPACY works good but it is not optimal always. Futhermore, if user wants to include user-defined entities it can be done with the help of training.\n",
    "\n",
    "### Built-in Entities in SPACY: \n",
    "    - PERSON : People, including fictional\n",
    "    - NORP : Nationalities or religious or political groups.\n",
    "    - FACILITY : Buildings, airports, highways, bridges, etc.\n",
    "    - ORG : Companies, agencies, institutions, etc.\n",
    "    - GPE : Countries, cities, states.\n",
    "    - LOC : Non-GPE locations, mountain ranges, bodies of water.\n",
    "    - PRODUCT : Objects, vehicles, foods, etc. (Not services.)\n",
    "    - WORK_OF_ART : Titles of books, songs, etc.\n",
    "    - LANGUAGE : Any named language.\n",
    "\n",
    "and many more can be found in source.\n",
    "\n",
    "source: https://spacy.io/docs/usage/entity-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "from spacy.en import English\n",
    "from __future__ import unicode_literals \n",
    "nlp = spacy.load('en')  # load english language module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pos_tagger:\n",
    "    \n",
    "    def __init__(self,parser):\n",
    "        self.parser = parser\n",
    "    \n",
    "    def pos_tag(self,sentence):\n",
    "        \"\"\" add part of speech tags for each string in sentence\n",
    "        args:\n",
    "            takes input as sentence\n",
    "        returns:\n",
    "            list containing strings with part of speech tags\n",
    "        \"\"\"\n",
    "        parseText = self.parser(sentence)\n",
    "        pos_tag_list = []\n",
    "        \n",
    "        for word in parseText:\n",
    "                pos_tag_list.append(word)\n",
    "                pos_tag_list.append(word.pos_)\n",
    "                print \"word : \", word,\" =======\", \" part of speech: \", word.pos_\n",
    "        return pos_tag_list\n",
    "    \n",
    "    '''\n",
    "    Input: sentence\n",
    "    Output: word having named entities\n",
    "    '''\n",
    "    def entity_recognition(self,sentence):\n",
    "        \n",
    "        doc = self.parser(sentence)\n",
    "        for word in doc:\n",
    "            #if word does not have any named entity, word.ent_type returns 0 \n",
    "            if (word.ent_type != 0):\n",
    "                print word, word.ent_type_\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word :  Germany  =======  part of speech:  PROPN\n",
      "word :  is  =======  part of speech:  VERB\n",
      "word :  famous  =======  part of speech:  ADJ\n",
      "word :  for  =======  part of speech:  ADP\n",
      "word :  cars  =======  part of speech:  NOUN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Germany, u'PROPN', is, u'VERB', famous, u'ADJ', for, u'ADP', cars, u'NOUN']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tag = pos_tagger(parser)\n",
    "text = \"Germany is famous for cars\"\n",
    "p_tag.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entity tags in sentence: \n",
      "Munich is a biggest city in Germany, Microsoft is really nice company and German is national language\n",
      "Munich GPE\n",
      "Germany GPE\n",
      "Microsoft ORG\n",
      "German NORP\n",
      "====================================================\n",
      "Named Entity tags in sentence: \n",
      "London is a big city in United Kingdom\n",
      "London GPE\n",
      "United GPE\n",
      "Kingdom GPE\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"Munich is a biggest city in Germany, Microsoft is really nice company and German is national language\"\n",
    "print \"Named Entity tags in sentence: \"\n",
    "print sentence1\n",
    "p_tag.entity_recognition(sentence1)\n",
    "print \"====================================================\"\n",
    "sentence2 = \"London is a big city in United Kingdom\"\n",
    "print \"Named Entity tags in sentence: \"\n",
    "print sentence2\n",
    "p_tag.entity_recognition(sentence2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
