{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Similarity using SPACY\n",
    "\n",
    "#### Spacy does not provides built-in Levenshtein distance, therefore I am using Levenshtein distance provided by python.\n",
    "\n",
    "It computes minimum edit distance between two strings by performing three operations:\n",
    "1. Substitution\n",
    "2. Insertion\n",
    "3. Deletion\n",
    "\n",
    "# Textacy\n",
    "\n",
    "Higher-level NLP built on Spacy\n",
    "\n",
    "#### N-grams are computed by using Textacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import textacy\n",
    "import collections\n",
    "import re\n",
    "import warnings\n",
    "from cytoolz import itertoolz\n",
    "from Levenshtein import (distance as edit_distance,\n",
    "                         hamming as _hamming,\n",
    "                         jaro_winkler as _jaro_winkler,\n",
    "                         ratio as _ratio)\n",
    "from spacy.en import English\n",
    "from __future__ import unicode_literals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class string_similarity:\n",
    "    \n",
    "    def __init__(self, parser):\n",
    "        \n",
    "        self.parser = parser\n",
    "            \n",
    "    '''\n",
    "    Given sentence and value of n(denotes how many grams of text)\n",
    "    n = 1 means unigram\n",
    "    n = 2 means bigram and so on\n",
    "    \n",
    "    return grams of text\n",
    "    '''\n",
    "    def find_ngrams(self,text,n):\n",
    "        \n",
    "        parse_text = self.parser(text)\n",
    "        \n",
    "        return list(textacy.extract.ngrams(parse_text,n,filter_stops=False, filter_punct=True, filter_nums=False))\n",
    "        \n",
    "    '''\n",
    "    Compute minimum edit distance between two strings\n",
    "    Operations performed: deletion, insertion and substitution\n",
    "    '''\n",
    "    def compute_levenshtein(self, str1, str2):\n",
    "\n",
    "        return edit_distance(str1, str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj = string_similarity(parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levenshtein distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.compute_levenshtein(\"hello\",\"hey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[I am, am trying, trying ngram, ngram using, using spacy]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I am trying ngram using spacy\"\n",
    "obj.find_ngrams(sentence,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
